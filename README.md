<!-- Profile README for Mohammadreza Tavasoli Naeini -->

<h1 align="center">
  Hi there, I'm Mohammadreza&nbsp;Tavasoli&nbsp;Naeini&nbsp;ğŸ‘‹
</h1>

---

### ğŸ”¬ Current focus
- **Generative Models** &nbsp;Â·&nbsp; Diffusion / GANsâ€ƒ&nbsp;
- **Bayes-Optimal Learning** - theory, bounds, & applications  
- **Computer Vision** - 3D scene understanding, high-fidelity synthesis  
- **Optimization for Deep Networks** - MPS-friendly PyTorch pipelines  

### âœ¨ Highlight projects
| Repo | What it does | Key tech |
|------|--------------|----------|
| [`bolt-loss`](https://github.com/MohammadrezaTavasoli/bolt-loss) | Reference code for â€œBayes Optimal Learning Threshold (BOLT) Lossâ€ â€“ plug-and-play loss to tighten Bayes error bounds in classifiers & GANs. | PyTorch Lightning â€¢ Hydra â€¢ W&B |
| [`quantum-lstm`](https://github.com/MohammadrezaTavasoli/Quantum-LSTM/tree/master/examples/quantum_lstm) | Hybrid Quantum-Classical LSTM built with Torch-Quantum | Torch-Quantum â€¢ Qiskit |
| [`quantum-transformer`](https://github.com/MohammadrezaTavasoli/Quantum-Transformer) | Hybrid Quantum-Classical Transformer implemented with Torch-Quantum| Torch-Quantum â€¢ Qiskit |


### ğŸ›  Tech toolbox
`Python` â€¢ `PyTorch` â€¢ `Lightning` â€¢ `Hydra` â€¢ `W&B`  
`CUDA / MPS` â€¢ `NumPy` â€¢ `Matplotlib` â€¢ `LaTeX` â€¢ `Git` â€¢ `Docker`

### ğŸš€ Selected achievements
- **ICASSP 2025** â€” _Universal Training of Neural Networks to Achieve Bayes-Optimal Classification_  
- Built a **neural adaptive streaming framework** (â€œPensieveâ€) clone with -8Â % rebuffering vs. baseline.  
- Reviewer for **IJCNN 2025** (Deep Generative Models track).

### ğŸ“« Connect
- Email: tavasoli@umich.edu
- LinkedIn: [linkedin.com/in/mohammadreza-tavasoli-naeini-88baa992](https://www.linkedin.com/in/mohammadreza-tavasoli-naeini-88baa992/)
- GoogleÂ Scholar: [scholar profile]([https://scholar.google.com/](https://scholar.google.ca/citations?user=b4frolwAAAAJ&hl=en))

---

<p align="center">
  <sub>Built with â¤ï¸ and â˜• &nbsp;|&nbsp; Last updated: 2025â€‘05â€‘15</sub>
</p>
